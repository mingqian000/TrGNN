{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mask ParsedTaxiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from datetime import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "import networkx as nx\n",
    "from utils import time_difference\n",
    "from road_graph import get_road_list, road_graph\n",
    "\n",
    "\n",
    "def read_GPS_dataset(date_range=['20160325', '20160325'], in_path='data/ParsedTaxiData_%s.csv', test_mode=False):\n",
    "    # date_range = [start_date, end_date]\n",
    "    print('Reading GPS dataset')\n",
    "    start_date, end_date = date_range\n",
    "    start_date, end_date = dt.strptime(start_date, '%Y%m%d'), dt.strptime(end_date, '%Y%m%d')\n",
    "    date_list = [(start_date + timedelta(i)).strftime('%Y%m%d') for i in range((end_date - start_date).days+1)]\n",
    "    column_names = ['vehicle_id', 'lon', 'lat', 'speed', 'direction', 'status', 'time', \n",
    "                    'closest_road_id', 'matched_lon', 'matched_lat', 'matched_road_id', 'matched_road_name']\n",
    "    if test_mode:\n",
    "        df_list = [pd.read_csv(in_path%(date), header=None, names=column_names, nrows=100000).drop_duplicates() for date in date_list]\n",
    "    else:\n",
    "        df_list = [pd.read_csv(in_path%(date), header=None, names=column_names).drop_duplicates() for date in date_list]\n",
    "    df = pd.concat(df_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Settings\n",
    "# start_date = '20160325'\n",
    "# end_date = '20160325'\n",
    "start_date = '20160314'\n",
    "end_date = '20160314'\n",
    "time_gap = 10 # threshold for trajectory extraction\n",
    "stay_duration = 2 # threshold for trajectory extraction\n",
    "speed_limit = 120 # threshold for trajectory extraction\n",
    "GPS_path = 'data/ParsedTaxiData_%s_v0.csv'\n",
    "road_list_path = 'data/road_list.csv'\n",
    "graph_path = 'data/road_graph.gml'\n",
    "trajectory_path = 'data/recovered_trajectory_df_%s_%s.csv'%(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road list exists\n",
      "Graph exists\n"
     ]
    }
   ],
   "source": [
    "road_list = get_road_list(road_df=None, out_path=road_list_path, update=False)\n",
    "G = road_graph(road_df=None, out_path=graph_path, update=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading GPS dataset\n"
     ]
    }
   ],
   "source": [
    "df = read_GPS_dataset(date_range=[start_date, end_date], in_path=GPS_path, test_mode=0)\n",
    "df = df.replace({'vehicle_id': 'SHA9148Z'}, {'vehicle_id': 'XXXXXXX'}\n",
    "          ).replace({'vehicle_id': 'SHC1124J'}, {'vehicle_id': 'YYYYYYY'})\n",
    "df = df[['vehicle_id', 'time', 'matched_road_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>time</th>\n",
       "      <th>matched_road_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:00</td>\n",
       "      <td>103047123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:05</td>\n",
       "      <td>103063511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:10</td>\n",
       "      <td>104004183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:20</td>\n",
       "      <td>103055323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:26</td>\n",
       "      <td>103055319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:35</td>\n",
       "      <td>103055311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:41</td>\n",
       "      <td>103007624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:50</td>\n",
       "      <td>103113967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:00:56</td>\n",
       "      <td>103113987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:05</td>\n",
       "      <td>103113963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:11</td>\n",
       "      <td>103113959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:21</td>\n",
       "      <td>103064855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:26</td>\n",
       "      <td>103065115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:36</td>\n",
       "      <td>103065159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:38</td>\n",
       "      <td>103061690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:41</td>\n",
       "      <td>103061690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:51</td>\n",
       "      <td>103115806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:01:56</td>\n",
       "      <td>103115810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:06</td>\n",
       "      <td>103065203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:11</td>\n",
       "      <td>103110423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:21</td>\n",
       "      <td>103065459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:26</td>\n",
       "      <td>103115463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:37</td>\n",
       "      <td>103115919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:42</td>\n",
       "      <td>103115915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:51</td>\n",
       "      <td>103115911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:02:57</td>\n",
       "      <td>103063631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:03:06</td>\n",
       "      <td>103064702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:03:12</td>\n",
       "      <td>103064759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:03:22</td>\n",
       "      <td>103064751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XXXXXXX</td>\n",
       "      <td>14/03/2016 00:03:28</td>\n",
       "      <td>103103499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:21:58</td>\n",
       "      <td>103013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:22:14</td>\n",
       "      <td>103013147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:22:25</td>\n",
       "      <td>103013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:22:37</td>\n",
       "      <td>103013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:22:37</td>\n",
       "      <td>103013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:22:38</td>\n",
       "      <td>103013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:23:10</td>\n",
       "      <td>103013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:23:30</td>\n",
       "      <td>103013962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:23:46</td>\n",
       "      <td>103110356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:23:56</td>\n",
       "      <td>108003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:02</td>\n",
       "      <td>103107231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:13</td>\n",
       "      <td>103079199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:22</td>\n",
       "      <td>103076451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:23</td>\n",
       "      <td>103076451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:35</td>\n",
       "      <td>103076451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:39</td>\n",
       "      <td>103076451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:42</td>\n",
       "      <td>103076451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:24:55</td>\n",
       "      <td>103075540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:25:05</td>\n",
       "      <td>103104052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:25:10</td>\n",
       "      <td>103104056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:25:21</td>\n",
       "      <td>103073216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:25:26</td>\n",
       "      <td>103066056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:25:38</td>\n",
       "      <td>103076404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:26:08</td>\n",
       "      <td>103076404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:26:39</td>\n",
       "      <td>103076404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:27:04</td>\n",
       "      <td>103093368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:27:35</td>\n",
       "      <td>103093372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:27:39</td>\n",
       "      <td>103093372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:27:50</td>\n",
       "      <td>103012818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>YYYYYYY</td>\n",
       "      <td>14/03/2016 00:27:52</td>\n",
       "      <td>103012818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    vehicle_id                 time  matched_road_id\n",
       "0      XXXXXXX  14/03/2016 00:00:00        103047123\n",
       "1      XXXXXXX  14/03/2016 00:00:05        103063511\n",
       "2      XXXXXXX  14/03/2016 00:00:10        104004183\n",
       "3      XXXXXXX  14/03/2016 00:00:20        103055323\n",
       "4      XXXXXXX  14/03/2016 00:00:26        103055319\n",
       "5      XXXXXXX  14/03/2016 00:00:35        103055311\n",
       "6      XXXXXXX  14/03/2016 00:00:41        103007624\n",
       "7      XXXXXXX  14/03/2016 00:00:50        103113967\n",
       "8      XXXXXXX  14/03/2016 00:00:56        103113987\n",
       "9      XXXXXXX  14/03/2016 00:01:05        103113963\n",
       "10     XXXXXXX  14/03/2016 00:01:11        103113959\n",
       "11     XXXXXXX  14/03/2016 00:01:21        103064855\n",
       "12     XXXXXXX  14/03/2016 00:01:26        103065115\n",
       "13     XXXXXXX  14/03/2016 00:01:36        103065159\n",
       "14     XXXXXXX  14/03/2016 00:01:38        103061690\n",
       "15     XXXXXXX  14/03/2016 00:01:41        103061690\n",
       "16     XXXXXXX  14/03/2016 00:01:51        103115806\n",
       "17     XXXXXXX  14/03/2016 00:01:56        103115810\n",
       "18     XXXXXXX  14/03/2016 00:02:06        103065203\n",
       "19     XXXXXXX  14/03/2016 00:02:11        103110423\n",
       "20     XXXXXXX  14/03/2016 00:02:21        103065459\n",
       "21     XXXXXXX  14/03/2016 00:02:26        103115463\n",
       "22     XXXXXXX  14/03/2016 00:02:37        103115919\n",
       "23     XXXXXXX  14/03/2016 00:02:42        103115915\n",
       "24     XXXXXXX  14/03/2016 00:02:51        103115911\n",
       "25     XXXXXXX  14/03/2016 00:02:57        103063631\n",
       "26     XXXXXXX  14/03/2016 00:03:06        103064702\n",
       "27     XXXXXXX  14/03/2016 00:03:12        103064759\n",
       "28     XXXXXXX  14/03/2016 00:03:22        103064751\n",
       "29     XXXXXXX  14/03/2016 00:03:28        103103499\n",
       "..         ...                  ...              ...\n",
       "168    YYYYYYY  14/03/2016 00:21:58        103013158\n",
       "169    YYYYYYY  14/03/2016 00:22:14        103013147\n",
       "170    YYYYYYY  14/03/2016 00:22:25        103013143\n",
       "171    YYYYYYY  14/03/2016 00:22:37        103013143\n",
       "173    YYYYYYY  14/03/2016 00:22:37        103013143\n",
       "174    YYYYYYY  14/03/2016 00:22:38        103013143\n",
       "175    YYYYYYY  14/03/2016 00:23:10        103013143\n",
       "176    YYYYYYY  14/03/2016 00:23:30        103013962\n",
       "177    YYYYYYY  14/03/2016 00:23:46        103110356\n",
       "178    YYYYYYY  14/03/2016 00:23:56        108003603\n",
       "179    YYYYYYY  14/03/2016 00:24:02        103107231\n",
       "181    YYYYYYY  14/03/2016 00:24:13        103079199\n",
       "182    YYYYYYY  14/03/2016 00:24:22        103076451\n",
       "183    YYYYYYY  14/03/2016 00:24:23        103076451\n",
       "184    YYYYYYY  14/03/2016 00:24:35        103076451\n",
       "185    YYYYYYY  14/03/2016 00:24:39        103076451\n",
       "186    YYYYYYY  14/03/2016 00:24:42        103076451\n",
       "187    YYYYYYY  14/03/2016 00:24:55        103075540\n",
       "188    YYYYYYY  14/03/2016 00:25:05        103104052\n",
       "189    YYYYYYY  14/03/2016 00:25:10        103104056\n",
       "190    YYYYYYY  14/03/2016 00:25:21        103073216\n",
       "191    YYYYYYY  14/03/2016 00:25:26        103066056\n",
       "192    YYYYYYY  14/03/2016 00:25:38        103076404\n",
       "193    YYYYYYY  14/03/2016 00:26:08        103076404\n",
       "194    YYYYYYY  14/03/2016 00:26:39        103076404\n",
       "195    YYYYYYY  14/03/2016 00:27:04        103093368\n",
       "196    YYYYYYY  14/03/2016 00:27:35        103093372\n",
       "197    YYYYYYY  14/03/2016 00:27:39        103093372\n",
       "198    YYYYYYY  14/03/2016 00:27:50        103012818\n",
       "199    YYYYYYY  14/03/2016 00:27:52        103012818\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/ParsedTaxiData_20160314.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trajectory transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/trajectory_transition_20160314_20160314.pkl', 'rb') as f:\n",
    "    trajectory_transition = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 2404, 2404)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_transition.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 2404)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../trajectory/result/RF_5hop_100estimator_Y_pred.pkl', 'rb') as f:\n",
    "    RF_result= pkl.load(f)\n",
    "RF_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.958333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1340/4/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import folium\n",
    "from utils import *\n",
    "import random\n",
    "import numpy as np\n",
    "from math import radians, degrees, sin, cos, asin, acos, sqrt\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from metrics import *\n",
    "from trajectory_transition import extract_trajectory_transition\n",
    "from road_graph import extract_road_adj\n",
    "from model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road adj exists\n",
      "Total file exists\n"
     ]
    }
   ],
   "source": [
    "model_name = 'TrGNN'\n",
    "dataset = 'demo'\n",
    "model_path = ''\n",
    "start_time = time.time()\n",
    "\n",
    "# Model and log\n",
    "models = {'TrGNN':Model_TrGNN, 'TrGNN-':Model_GNN}\n",
    "model = models[model_name]()\n",
    "if model_path == '': # if no pre-trained model path\n",
    "    prefix = '%s_%s'%(model_name, int(start_time))\n",
    "    checkpoint_epoch = -1\n",
    "if os.path.isfile(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    prefix = '_'.join(model_path.split('_')[:2])\n",
    "    checkpoint_epoch = int(model_path.split('_')[-1][:-9])\n",
    "model_path = 'model/%s_%sepoch.cpt'%(prefix, '%d')\n",
    "log_path = 'log/%s.log'%prefix\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print_log(device, log_path)\n",
    "\n",
    "\n",
    "# Dataset\n",
    "# 'sg_expressway_4weeks', 'sg_expressway_8weeks'\n",
    "road_adj = extract_road_adj() # directed adj\n",
    "\n",
    "if dataset == 'demo':\n",
    "    start_date, end_date = '20160314', '20160314'\n",
    "    calibrate = False\n",
    "elif dataset == 'sg_expressway_8weeks':\n",
    "    start_date, end_date = '20160314', '20160424' # train period + validation period\n",
    "else:\n",
    "    start_date, end_date = '20160401', '20160421' # train period + validation period\n",
    "trajectory_transition = extract_trajectory_transition(start_date, end_date)\n",
    "# smoothing with binary road_adj, in case no historical flow is recorded.\n",
    "road_adj_mask = np.zeros(road_adj.shape)\n",
    "road_adj_mask[road_adj > 0] = 1\n",
    "np.fill_diagonal(road_adj_mask, 0)\n",
    "for i in range(len(trajectory_transition)):\n",
    "    trajectory_transition[i] = trajectory_transition[i] + road_adj_mask\n",
    "\n",
    "if dataset == 'demo':\n",
    "    start_date, end_date = '20160314', '20160314'\n",
    "    calibrate = False\n",
    "elif dataset == 'sg_expressway_8weeks':\n",
    "    start_date, end_date = '20160314', '20160508' # train (5 weeks) + validation (1 week) + test (2 weeks)\n",
    "else:\n",
    "    start_date, end_date = '20160401', '20160428' # train + validation + test\n",
    "dates = date_range(start_date, end_date)\n",
    "flow_df = pd.concat([pd.read_csv('data/flow_%s_%s.csv'%(date, date), index_col=0) for date in dates])\n",
    "flow_df.columns = pd.Index(int(road_id) for road_id in flow_df.columns)\n",
    "# flow calibration on a daily basis\n",
    "if calibrate:\n",
    "    print_log('Calibrating flow...', log_path)\n",
    "    trajectory_metadata = pd.read_csv('data/trajectory_metadata.csv') # read trajectory metadata\n",
    "    multipliers = np.repeat(np.array(trajectory_metadata['vehicles'][0] / trajectory_metadata['vehicles']), 96)\n",
    "    multipliers[multipliers==np.inf]=0\n",
    "    flow_df = flow_df.mul(multipliers, axis=0)\n",
    "print_log(flow_df.shape, log_path)\n",
    "print_log('Total flow: %d'%(flow_df.sum().sum()), log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'demo': # 20160314\n",
    "    indices = {'train': list(range(56)), # first 14 hours\n",
    "               'val': list(range(56, 68)), # next 3 hours\n",
    "               'test': list(range(68, 92))} # last 6 hours\n",
    "    weekdays = np.array([0]) # day 0 (i.e. 20160314) is a weekday\n",
    "elif dataset == 'sg_expressway_8weeks': # version 20160314-20160508\n",
    "    indices = {'train': list(range(3220)), # first 5 weeks 20160314-20160417 (24-1)*(60/15)*56\n",
    "               'val': list(range(3220, 3864)), # 6th week 20160418-20160424 (24-1)*(60/15)*7\n",
    "               'test': list(range(3864, 5152))} # 7th-8th weeks 20160425-20160508 (24-1)*(60/15)*14\n",
    "    # indices of weekdays (exclude weekends and PHs)\n",
    "    weekdays = np.array([0, 1, 2, 3, 4, \n",
    "                         7, 8, 9, 10, # PH: 25th May, Friday\n",
    "                         14, 15, 16, 17, 18,\n",
    "                         21, 22, 23, 24, 25,\n",
    "                         28, 29, 30, 31, 32, \n",
    "                         35, 36, 37, 38, 39,\n",
    "                         42, 43, 44, 45, 46, \n",
    "                         50, 51, 52, 53]) # PH: 2nd May, Monday\n",
    "else: # version 20160401-20160428\n",
    "    indices = {'train': list(range(1288)), # first two weeks (24-1)*(60/15)*14\n",
    "               'val': list(range(1288, 1932)), # third week (24-1)*(60/15)*7\n",
    "               'test': list(range(1932, 2576))} # fourth week (24-1)*(60/15)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 2404)\n"
     ]
    }
   ],
   "source": [
    "print(flow_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demo'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices['train'] + indices['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_df.iloc[indices['train'] + indices['val']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2404)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('result/TrGNN_1596949116_0epoch_Y_pred.pkl', 'rb') as f:\n",
    "    Y_pred = pkl.load(f)\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
